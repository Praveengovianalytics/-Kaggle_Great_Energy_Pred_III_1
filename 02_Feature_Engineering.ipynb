{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/praveengovindaraj/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc, math\n",
    "\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_without_overflow_fast(col):\n",
    "    col /= len(col)\n",
    "    return col.mean() * len(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degToCompass(num):\n",
    "    val=int((num/22.5)+.5)\n",
    "    arr=[i for i in range(0,16)]\n",
    "    return arr[(val % 16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.8 s, sys: 3.21 s, total: 51 s\n",
      "Wall time: 51.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metadata_df = pd.read_csv('data/building_metadata.csv')\n",
    "train_df = pd.read_csv('data/train.csv', parse_dates=['timestamp'])\n",
    "test_df = pd.read_csv('data/test.csv', parse_dates=['timestamp'])\n",
    "weather_train_df = pd.read_csv('data/weather_train.csv', parse_dates=['timestamp'])\n",
    "weather_test_df = pd.read_csv('data/weather_test.csv', parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align timestamps\n",
    "\n",
    "Timestap data is not in their local time. As energy consumptions are related to the local time, an alighment is nescessary before using timestamp.\n",
    "\n",
    "The credit goes to this https://www.kaggle.com/nz0722/aligned-timestamp-lgbm-by-meter-type  for the idea. Refer it for more details and explanation about below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.concat([weather_train_df,weather_test_df],ignore_index=True)\n",
    "weather_key = ['site_id', 'timestamp']\n",
    "\n",
    "temp_skeleton = weather[weather_key + ['air_temperature']].drop_duplicates(subset=weather_key).sort_values(by=weather_key).copy()\n",
    "\n",
    "# calculate ranks of hourly temperatures within date/site_id chunks\n",
    "\n",
    "temp_skeleton['temp_rank'] = temp_skeleton.groupby(['site_id', temp_skeleton.timestamp.dt.date])['air_temperature'].rank('average')\n",
    "\n",
    "# create a dataframe of site_ids (0-16) x mean hour rank of temperature within day (0-23)\n",
    "df_2d = temp_skeleton.groupby(['site_id', temp_skeleton.timestamp.dt.hour])['temp_rank'].mean().unstack(level=1)\n",
    "\n",
    "# Subtract the columnID of temperature peak by 14, getting the timestamp alignment gap.\n",
    "site_ids_offsets = pd.Series(df_2d.values.argmax(axis=1) - 14)\n",
    "site_ids_offsets.index.name = 'site_id'\n",
    "\n",
    "def timestamp_align(df):\n",
    "    df['offset'] = df.site_id.map(site_ids_offsets)\n",
    "    df['timestamp_aligned'] = (df.timestamp - pd.to_timedelta(df.offset, unit='H'))\n",
    "    df['timestamp'] = df['timestamp_aligned']\n",
    "    del df['timestamp_aligned']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_df = timestamp_align(weather_train_df)\n",
    "weather_test_df = timestamp_align(weather_test_df)\n",
    "\n",
    "del weather \n",
    "del df_2d\n",
    "del temp_skeleton\n",
    "del site_ids_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['meter_reading'] = np.log1p(train_df['meter_reading'])\n",
    "le = LabelEncoder()\n",
    "metadata_df['primary_use'] = le.fit_transform(metadata_df['primary_use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.02 Mb (74.9% reduction)\n",
      "Mem. usage decreased to 250.63 Mb (59.4% reduction)\n",
      "Mem. usage decreased to 596.49 Mb (53.1% reduction)\n",
      "Mem. usage decreased to  3.20 Mb (70.0% reduction)\n",
      "Mem. usage decreased to  6.35 Mb (70.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "metadata_df = reduce_mem_usage(metadata_df)\n",
    "train_df = reduce_mem_usage(train_df)\n",
    "test_df = reduce_mem_usage(test_df)\n",
    "weather_train_df = reduce_mem_usage(weather_train_df)\n",
    "weather_test_df = reduce_mem_usage(weather_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (20216100, 4)\n",
      "Weather training shape: (139773, 10)\n",
      "Weather training shape: (277243, 10)\n",
      "Weather testing shape: (1449, 6)\n",
      "Test data shape: (41697600, 4)\n"
     ]
    }
   ],
   "source": [
    "print (f'Training data shape: {train_df.shape}')\n",
    "print (f'Weather training shape: {weather_train_df.shape}')\n",
    "print (f'Weather training shape: {weather_test_df.shape}')\n",
    "print (f'Weather testing shape: {metadata_df.shape}')\n",
    "print (f'Test data shape: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.19 s, sys: 2.9 s, total: 9.09 s\n",
      "Wall time: 9.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full_train_df = train_df.merge(metadata_df, on='building_id', how='left')\n",
    "full_train_df = full_train_df.merge(weather_train_df, on=['site_id', 'timestamp'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete unnecessary dataframes to decrease memory usage\n",
    "del train_df\n",
    "del weather_train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['building_id', 'meter', 'timestamp', 'meter_reading', 'site_id',\n",
       "       'primary_use', 'square_feet', 'year_built', 'floor_count',\n",
       "       'air_temperature', 'cloud_coverage', 'dew_temperature',\n",
       "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
       "       'wind_speed', 'offset'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 s, sys: 6.31 s, total: 19 s\n",
      "Wall time: 19.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# full_test_df = test_df.merge(metadata_df, on='building_id', how='left')\n",
    "# full_test_df = full_test_df.merge(weather_test_df, on=['site_id', 'timestamp'], how='left')\n",
    "full_test_df = test_df.merge(metadata_df, on='building_id', how='left')\n",
    "full_test_df = full_test_df.merge(weather_test_df, on=['site_id', 'timestamp'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "full_train_df['primary_use'] = le.fit_transform(full_train_df['primary_use']).astype(np.int8)\n",
    "full_test_df['primary_use'] = le.fit_transform(full_test_df['primary_use']).astype(np.int8)\n",
    "\n",
    "full_train_df['square_feet'] = np.log(full_train_df['square_feet'])\n",
    "full_test_df['square_feet'] = np.log(full_test_df['square_feet'])\n",
    "full_train_df['age'] = full_train_df['year_built'].max() - full_train_df['year_built'] + 1\n",
    "full_test_df['age'] = full_test_df['year_built'].max() - full_test_df['year_built'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaN Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>floor_count</th>\n",
       "      <td>16709167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_built</th>\n",
       "      <td>12127645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>12127645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloud_coverage</th>\n",
       "      <td>8831471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <td>3758784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind_direction</th>\n",
       "      <td>1461546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <td>1242486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind_speed</th>\n",
       "      <td>156584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dew_temperature</th>\n",
       "      <td>113100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_temperature</th>\n",
       "      <td>109618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset</th>\n",
       "      <td>103451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>square_feet</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>primary_use</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site_id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meter_reading</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meter</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    NaN Count\n",
       "floor_count          16709167\n",
       "year_built           12127645\n",
       "age                  12127645\n",
       "cloud_coverage        8831471\n",
       "precip_depth_1_hr     3758784\n",
       "wind_direction        1461546\n",
       "sea_level_pressure    1242486\n",
       "wind_speed             156584\n",
       "dew_temperature        113100\n",
       "air_temperature        109618\n",
       "offset                 103451\n",
       "square_feet                 0\n",
       "primary_use                 0\n",
       "site_id                     0\n",
       "meter_reading               0\n",
       "timestamp                   0\n",
       "meter                       0\n",
       "building_id                 0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(full_train_df.isna().sum().sort_values(ascending=False), columns=['NaN Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = (100-full_train_df.count() / len(full_train_df) * 100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.64 s, sys: 4.2 s, total: 7.84 s\n",
      "Wall time: 3.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "missing_features = full_train_df.loc[:, missing_values > 0.0]\n",
    "missing_features = missing_features.apply(mean_without_overflow_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in full_train_df.loc[:, missing_values > 0.0].keys():\n",
    "    if key == 'year_built' or key == 'floor_count':\n",
    "        full_train_df[key].fillna(math.floor(missing_features[key]), inplace=True)\n",
    "        full_test_df[key].fillna(math.floor(missing_features[key]), inplace=True)\n",
    "    else:\n",
    "        full_train_df[key].fillna(missing_features[key], inplace=True)\n",
    "        full_test_df[key].fillna(missing_features[key], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    df['hour'] = np.uint8(df['timestamp'].dt.hour)\n",
    "    df['day'] = np.uint8(df['timestamp'].dt.day)\n",
    "    df['weekday'] = np.uint8(df['timestamp'].dt.weekday)\n",
    "    df['month'] = np.uint8(df['timestamp'].dt.month)\n",
    "    df['year'] = np.uint8(df['timestamp'].dt.year-1900)\n",
    "    df['square_feet_floor']=df['square_feet']/df['floor_count']\n",
    "    df['square_feet_floor']=np.log(df['square_feet_floor'])\n",
    "    df['square_feet'] = np.log(df['square_feet'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag_feature(weather_df, window=3):\n",
    "    group_df = weather_df.groupby('site_id')\n",
    "    cols = ['air_temperature', 'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed']\n",
    "    rolled = group_df[cols].rolling(window=window, min_periods=0)\n",
    "    lag_mean = rolled.mean().reset_index().astype(np.float16)\n",
    "    lag_max = rolled.max().reset_index().astype(np.float16)\n",
    "    lag_min = rolled.min().reset_index().astype(np.float16)\n",
    "    lag_std = rolled.std().reset_index().astype(np.float16)\n",
    "    for col in cols:\n",
    "        weather_df[f'{col}_mean_lag{window}'] = lag_mean[col]\n",
    "        weather_df[f'{col}_max_lag{window}'] = lag_max[col]\n",
    "        weather_df[f'{col}_min_lag{window}'] = lag_min[col]\n",
    "        weather_df[f'{col}_std_lag{window}'] = lag_std[col]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_df = transform(full_train_df)\n",
    "full_test_df = transform(full_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_lag_feature(full_train_df, window=3)\n",
    "add_lag_feature(full_train_df, window=72)\n",
    "\n",
    "add_lag_feature(full_test_df, window=3)\n",
    "add_lag_feature(full_test_df, window=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_range = pd.date_range(start='2015-12-31', end='2019-01-01')\n",
    "us_holidays = calendar().holidays(start=dates_range.min(), end=dates_range.max())\n",
    "full_train_df['is_holiday'] = (full_train_df['timestamp'].dt.date.astype('datetime64').isin(us_holidays)).astype(np.int8)\n",
    "full_test_df['is_holiday'] = (full_test_df['timestamp'].dt.date.astype('datetime64').isin(us_holidays)).astype(np.int8)\n",
    "\n",
    "# Assuming 5 days a week for all the given buildings\n",
    "full_train_df.loc[(full_train_df['weekday'] == 5) | (full_train_df['weekday'] == 6) , 'is_holiday'] = 1\n",
    "full_test_df.loc[(full_test_df['weekday']) == 5 | (full_test_df['weekday'] == 6) , 'is_holiday'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_df = full_train_df.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training dataset: (19869886, 80)\n",
      "Shape of testing dataset: (41697600, 80)\n"
     ]
    }
   ],
   "source": [
    "full_test_df = full_test_df.drop(['timestamp'], axis=1)\n",
    "full_train_df = full_train_df.drop(['timestamp'], axis=1)\n",
    "print (f'Shape of training dataset: {full_train_df.shape}')\n",
    "print (f'Shape of testing dataset: {full_test_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 3012.95 Mb (10.2% reduction)\n",
      "Mem. usage decreased to 6402.31 Mb (10.1% reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reducing memory\n",
    "full_train_df = reduce_mem_usage(full_train_df)\n",
    "full_test_df = reduce_mem_usage(full_test_df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_cols = ['wind_direction','wind_direction_mean_lag3','wind_direction_max_lag3', 'wind_direction_min_lag3','wind_direction_std_lag3', 'wind_speed_mean_lag3',\n",
    "'wind_speed_max_lag3', 'wind_speed_min_lag3', 'wind_speed_std_lag3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wind_direction               0\n",
       "wind_direction_mean_lag3     0\n",
       "wind_direction_max_lag3      0\n",
       "wind_direction_min_lag3      0\n",
       "wind_direction_std_lag3     15\n",
       "wind_speed_mean_lag3         0\n",
       "wind_speed_max_lag3          0\n",
       "wind_speed_min_lag3          0\n",
       "wind_speed_std_lag3         15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_df[wind_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is the hot 🥵 fix for the expense of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_df['wind_direction_std_lag3'].fillna(0,inplace=True)\n",
    "full_train_df['wind_speed_std_lag3'].fillna(0,inplace=True)\n",
    "full_test_df['wind_direction_std_lag3'].fillna(0,inplace=True)\n",
    "full_test_df['wind_speed_std_lag3'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wcol in wind_cols:\n",
    "    full_train_df[wcol] = full_train_df[wcol].apply(degToCompass)\n",
    "    full_test_df[wcol] = full_test_df[wcol].apply(degToCompass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "beaufort = [(0, 0, 0.3), (1, 0.3, 1.6), (2, 1.6, 3.4), (3, 3.4, 5.5), (4, 5.5, 8), (5, 8, 10.8), (6, 10.8, 13.9), \n",
    "          (7, 13.9, 17.2), (8, 17.2, 20.8), (9, 20.8, 24.5), (10, 24.5, 28.5), (11, 28.5, 33), (12, 33, 200)]\n",
    "\n",
    "for item in beaufort:\n",
    "    full_train_df.loc[(full_train_df['wind_speed']>=item[1]) & (full_train_df['wind_speed']<item[2]), 'beaufort_scale'] = item[0]\n",
    "    full_test_df.loc[(full_test_df['wind_speed']>=item[1]) & (full_test_df['wind_speed']<item[2]), 'beaufort_scale'] = item[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 2880.31 Mb (31.2% reduction)\n",
      "Mem. usage decreased to 6123.95 Mb (30.9% reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_df = reduce_mem_usage(full_train_df)\n",
    "full_test_df = reduce_mem_usage(full_test_df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export engineered data for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the testing dataset to freeup the RAM. We'll read after training\n",
    "full_test_df.to_pickle('tmp/full_test_df.pkl')\n",
    "full_train_df.to_pickle('tmp/full_train_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-35-0a58694ad6d2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-0a58694ad6d2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ==================\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "=================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from featexp import get_trend_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = get_trend_stats(data=full_train_df, target_col='meter_reading', data_test=full_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
